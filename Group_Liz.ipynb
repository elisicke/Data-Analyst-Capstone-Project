{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the name of the csv file you want to read in\n",
    "accounts = './data/accounts.csv'\n",
    "playbacks = './data/playbacks.csv'\n",
    "subscriptions = './data/subscriptions.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Kanton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "kanton = './data/plz_verzeichnis.csv'\n",
    "df_kanton = pd.read_csv(kanton, sep=';')\n",
    "#df_kanton.columns = df_cntrycd.columns.str.lower()\n",
    "display(df_kanton.shape)\n",
    "display(df_kanton.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBSCRIPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read subscriptions\n",
    "df_subscriptions = pd.read_csv(subscriptions)\n",
    "df_subscriptions.columns = df_subscriptions.columns.str.lower()\n",
    "\n",
    "display(df_subscriptions.shape)\n",
    "display(df_subscriptions.head(10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subscriptions.groupby(['currency','price']).subscription_type.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set data types for subscription dates to datetime\n",
    "df_subscriptions['subscription_start'] = pd.to_datetime(df_subscriptions['subscription_start'])\n",
    "df_subscriptions['subscription_end'] = pd.to_datetime(df_subscriptions['subscription_end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create new 'clean' DataFrame \n",
    "df_subscriptions_clean = df_subscriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop \"wrong\" subscription type line (FULLACCESS - unknown type to us - only one line therefore decided to drop)\n",
    "df_subscriptions_clean.drop(df_subscriptions_clean[(df_subscriptions['subscription_type'] == 'FULLACCESS')].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column and calculate subscription duration for calculating actual price per subscription\n",
    "df_subscriptions_clean['subscription_months_raw'] = ((df_subscriptions_clean.subscription_end) - df_subscriptions_clean.subscription_start)/np.timedelta64(1, 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column with rounded subscription months\n",
    "#generally round up from 0.1 to be able to allow some discrepancies due to day to day calculation of subscription duration (deduct 0.1 to be able to use .ceil)\n",
    "df_subscriptions_clean['subscription_months'] = df_subscriptions_clean['subscription_months_raw'] - 0.1\n",
    "df_subscriptions_clean['subscription_months'] = df_subscriptions_clean['subscription_months'].apply(np.ceil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two columns for chf and eur based on the subscription_type and prices from the filmingo website\n",
    "\n",
    "# create a list of our conditions\n",
    "conditions = [\n",
    "    ((df_subscriptions_clean['subscription_type'] == 'BASIC') & (df_subscriptions_clean['subscription_monthly'] == 0)),\n",
    "    ((df_subscriptions_clean['subscription_type'] == 'BASIC') & (df_subscriptions_clean['subscription_monthly'] == 1)),\n",
    "    ((df_subscriptions_clean['subscription_type'] == 'STANDARD') & (df_subscriptions_clean['subscription_monthly'] == 0)),\n",
    "    ((df_subscriptions_clean['subscription_type'] == 'STANDARD') & (df_subscriptions_clean['subscription_monthly'] == 1)),\n",
    "    ((df_subscriptions_clean['subscription_type'] == 'PATRON') & (df_subscriptions_clean['subscription_monthly'] == 0))\n",
    "\n",
    "]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values_chf = ['90.0', '9.0', '150.0', '15.0', '240.0']\n",
    "values_eur = ['75.0', '7.5', '125.0', '12.5', '200.0']\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df_subscriptions_clean['price_chf'] = np.select(conditions, values_chf)\n",
    "df_subscriptions_clean['price_eur'] = np.select(conditions, values_eur)\n",
    "\n",
    "#change datatype into float for further calculation\n",
    "df_subscriptions_clean['price_chf'] = df_subscriptions_clean.price_chf.astype('float')\n",
    "df_subscriptions_clean['price_eur'] = df_subscriptions_clean.price_eur.astype('float')\n",
    "\n",
    "# decided to use these prices for all subscriptions regardless if they might have a different prices in the list (possibly due to discounts, total lines of abnormal prices: 39) or are gifted subscription (price: NaN, total lines 1.636)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate total price per subscription (price / 12 * subscription months)\n",
    "df_subscriptions_clean['total_price_chf'] = df_subscriptions_clean['price_chf'] / 12 * df_subscriptions_clean['subscription_months']\n",
    "df_subscriptions_clean['total_price_eur'] = df_subscriptions_clean['price_eur'] / 12 * df_subscriptions_clean['subscription_months']\n",
    "\n",
    "# conditional calculation for exceptions:\n",
    "\n",
    "# if the subscription is monthly only calculate price * months\n",
    "df_subscriptions_clean.loc[(df_subscriptions_clean['subscription_monthly'] == 1), 'total_price_chf'] = (df_subscriptions_clean['price_chf'] * df_subscriptions_clean['subscription_months'])\n",
    "df_subscriptions_clean.loc[(df_subscriptions_clean['subscription_monthly'] == 1), 'total_price_eur'] = (df_subscriptions_clean['price_eur'] * df_subscriptions_clean['subscription_months'])\n",
    "\n",
    "# if the subscription is gifted and 6 months long, a different price is applicable (there is only a 6 month subscription available for gifted subscriptions)\n",
    "df_subscriptions_clean.loc[((df_subscriptions_clean['gift_subscription'] == True) & (df_subscriptions_clean['subscription_months'] == 6)), 'total_price_chf'] = '49'\n",
    "df_subscriptions_clean.loc[((df_subscriptions_clean['gift_subscription'] == True) & (df_subscriptions_clean['subscription_months'] == 6)), 'total_price_eur'] = '41'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subscriptions_clean.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "df_subscriptions_clean.query('gift_subscription == True')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#test\n",
    "df_subscriptions_clean.query('subscription_monthly == 1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(gifted_df.groupby('subscription_months').max())\n",
    "print(df_subscriptions_clean.groupby(['subscription_months','subscription_monthly']).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_subscriptions_clean.to_csv('./data/subcriptions_clean.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gifted_df= df_subscriptions_clean.loc[df_subscriptions_clean['gift_subscription']==True]\n",
    "# gifted_df['months'] = gifted_df['subscription_months'].round()\n",
    "# gifted_df.tail(15)\n",
    "# #display(gifted_df.groupby('subscription_months').max())\n",
    "# gifted_df.groupby('months').sum()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nongifted_df= df_subscriptions_clean.loc[df_subscriptions_clean['gift_subscription']==False]\n",
    "\n",
    "# nongifted_df.groupby(['months', 'subscription_monthly']).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nongifted_df.query('account_key == b43a87d35bf285afdbb1c931b68ea2e6dad1f9dcc62947')\n",
    "\n",
    "#nongifted_df[nongifted_df['account_key'].str.contains('d8aa9f6793e94bc168a65808c9fe5809d4516448eae392a33edec16391c71d1e', na=False)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_subscriptions_clean = df_subscriptions_clean.drop('calc_price_chf', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCOUNTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read accounts (21.10.2020 - 01.10.2022)\n",
    "df_accounts = pd.read_csv(accounts)\n",
    "# set column names to lowercase\n",
    "df_accounts.columns = df_accounts.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(22154, 8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accounts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postal Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# todo drop duplicates from vouchers for merge\n",
    "# add voucher information to accounts table - have to add both columns\n",
    "df_accounts_new = pd.merge(df_accounts, df_vouchers [['email_hash_receiver', 'voucher_used']], left_on='email_hash', right_on='email_hash_receiver', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non numeric characters\n",
    "df_accounts['postal_code_clean'] = df_accounts['postal_code'].str.replace('-', '')\n",
    "df_accounts['postal_code_clean'] = df_accounts['postal_code_clean'].str.extract('(\\d+)')\n",
    "# fill null-values with 0\n",
    "df_accounts['postal_code_clean'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type to integer\n",
    "df_accounts['postal_code_clean'] = df_accounts['postal_code_clean'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping plz_files to accounts table for further geographical information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set file paths\n",
    "plz_ch = './data/plz_verzeichnis_ch.csv'\n",
    "plz_kanton = './data/plz_kantone_ch.csv'\n",
    "plz_de = './data/plz_verzeichnis_de.csv'\n",
    "plz_at = './data/plz_verzeichnis_at.csv'\n",
    "# read csv files\n",
    "df_plz_ch = pd.read_csv(plz_ch, sep=';')\n",
    "df_plz_kanton = pd.read_csv(plz_kanton, sep=';')\n",
    "df_plz_de = pd.read_csv(plz_de, sep=',')\n",
    "df_plz_at = pd.read_csv(plz_at, sep=';')\n",
    "# set column names to lowercase\n",
    "df_plz_ch.columns = df_plz_ch.columns.str.lower()\n",
    "df_plz_kanton.columns = df_plz_kanton.columns.str.lower()\n",
    "df_plz_de.columns = df_plz_de.columns.str.lower()\n",
    "df_plz_at.columns = df_plz_at.columns.str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean plz_kanton\n",
    "# only keep relevant columns, rename\n",
    "df_plz_kanton = df_plz_kanton[['postleitzahl / code postal / codice postale', 'ort / ville / città', 'kanton']]\n",
    "df_plz_kanton.rename(columns = {'postleitzahl / code postal / codice postale':'postal_code', 'ort / ville / città':'city', 'kanton':'state'}, inplace = True)\n",
    "df_plz_kanton.drop_duplicates(inplace = True)\n",
    "# add country_code for differentiation\n",
    "df_plz_kanton['country_code'] = 'CH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean plz_de\n",
    "# only keep relevant columns, rename, drop duplicates\n",
    "df_plz_de = df_plz_de[['plz', 'ort', 'bundesland']]\n",
    "df_plz_de.rename(columns = {'plz':'postal_code', 'ort':'city', 'bundesland':'state'}, inplace = True)\n",
    "df_plz_de.drop_duplicates(inplace = True)\n",
    "# add country_code for differentiation\n",
    "df_plz_de['country_code'] = 'DE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean plz_at\n",
    "# only keep relevant columns, rename, drop duplicates\n",
    "df_plz_at = df_plz_at[['plz', 'ort', 'bundesland']]\n",
    "df_plz_at.rename(columns = {'plz':'postal_code', 'ort':'city', 'bundesland':'state'}, inplace = True)\n",
    "df_plz_at.drop_duplicates(inplace = True)\n",
    "# add country_code for differentiation\n",
    "df_plz_at['country_code'] = 'AT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unify for merging, check shape\n",
    "df_plz_all = pd.concat([df_plz_kanton, df_plz_de, df_plz_at])\n",
    "# dropping plz duplicates with multiple city, keeping the first entry each\n",
    "df_plz_all = df_plz_all.groupby(['postal_code'])['city', 'state', 'country_code'].first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge city and state information to accounts table on plz and country code\n",
    "df_accounts = pd.merge(df_accounts, df_plz_all, left_on=['postal_code_clean', 'country_code'], right_on=['postal_code', 'country_code'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean plz_ch for language information\n",
    "# only keep relevant columns, rename, drop duplicates\n",
    "df_plz_ch = df_plz_ch[['postleitzahl', 'sprachcode']]\n",
    "df_plz_ch.rename(columns = {'postleitzahl':'postal_code'}, inplace = True)\n",
    "df_plz_ch.drop_duplicates(inplace=True)\n",
    "# add country_code for differentiation\n",
    "df_plz_ch['country_code'] = 'CH'\n",
    "\n",
    "'''\n",
    "Mapping of the language code:\n",
    "#1 = German  \n",
    "#2 = French  \n",
    "#3 = Italian \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge language code to accounts table\n",
    "df_accounts = pd.merge(df_accounts, df_plz_ch, left_on=['postal_code_clean', 'country_code'], right_on=['postal_code', 'country_code'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicate postal code columns\n",
    "df_accounts = df_accounts.drop(['postal_code_x', 'postal_code_y', 'postal_code'], axis=1)\n",
    "#rename original postal code column\n",
    "df_accounts.rename(columns = {'postal_code_x':'postal_code_original', 'city_x':'city_original', 'city_y':'city_clean'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accounts.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country_Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add country name and region information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add country information\n",
    "country= './data/country_code.csv'\n",
    "df_country = pd.read_csv(country)\n",
    "# make column names lowercase\n",
    "df_country.columns = df_country.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep relevant columns, rename\n",
    "df_country = df_country[['name', 'alpha-2', 'region', 'sub-region']]\n",
    "df_country.rename(columns = {'alpha-2':'country_code', 'name':'country_name', 'sub-region':'sub_region'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge to accounts_new table\n",
    "df_accounts = pd.merge(df_accounts, df_country, on='country_code', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill null values\n",
    "df_accounts['language'].fillna('na', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accounts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vouchers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Findings summary:\n",
    "* Multiple vouchers sent to the same email ( max 14 times) -> not really idea of voucher campaign -> not a \"new customer\"  \n",
    "* most of these multiple sent vouchers come from the same account -> account sharing? -> but looks like more individual cases  \n",
    "* approx. 50% do not redeem their voucher  \n",
    "* 718 unique email_hash connected to an accounts (of 5827 -> 12%)\n",
    "\n",
    "Possible further investigation:\n",
    "* how many email_hashes which were sent only 1/2 vouchers -> more in line with campaign idea\n",
    "* the emails with multiple vouchers sent -> are they paying customer as well?\n",
    "* How many of the 718 accounts have a subscription / OTR?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths to csv files\n",
    "accounts = './data/accounts.csv'\n",
    "playbacks = './data/playbacks.csv'\n",
    "subscriptions = './data/subscriptions.csv'\n",
    "vouchers = './data/promo_vouchers.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read promo_couchers\n",
    "df_vouchers = pd.read_csv(vouchers, sep=';')\n",
    "# set column names to lowercase\n",
    "df_vouchers.columns = df_vouchers.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vouchers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing datatype to datetime\n",
    "df_vouchers['creationdate'] = pd.to_datetime(df_vouchers['creationdate'])\n",
    "df_vouchers['expirationdate'] = pd.to_datetime(df_vouchers['expirationdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut off time of creation -> time not relevant? \n",
    "#df_vouchers['creationdate'] = df_vouchers['creationdate'].dt.date -> does not work very well as it returns an object\n",
    "df_vouchers['creationdate'] = df_vouchers['creationdate'].dt.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vouchers.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminary EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vouchers.groupby(['email_hash']).count().sort_values(by='account_key', ascending=False)\n",
    "# 14 times shared to same account - not idea of promo campaign -> not a \"new customer\" -> possibly only individual cases\n",
    "# ToDo: check how many cases are 1 / lower than 2 for example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_vouchers_acc.groupby(['email_hash']).count().sort_values(by='account_key_x', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vouchers.groupby(['email_hash', 'account_key']).count().sort_values(by='movie_id', ascending=False)\n",
    "#most emails on top get vouchers from same account_key "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vouchers.groupby(['voucherused']).count().sort_values(by='movie_id', ascending=False)\n",
    "# approx 50% do not redeem their voucher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge vouchers and accounts - not used as it takes in all information from accounts (possibly needed later)\n",
    "# df_vouchers_new = df_vouchers.merge(df_accounts, how='left', on='email_hash')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merges but only add the relevant columns for easier processing (here: account_key, subcription count and OTR count)\n",
    "df_vouchers_new = pd.merge(df_vouchers, df_accounts [['email_hash', 'account_key', 'subscription_count', 'onetime_rental_count']], on='email_hash', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vouchers_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df_vouchers_acc.account_key_y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_vouchers_new.shape)\n",
    "df_vouchers_new['account_key_y'].isna().sum()\n",
    "# 6619 NaN (no account connected) of 7790 (so 1.171 emails with account connected)-> also be aware of multiples in vouchers.email_hash -> see code below for this\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vouchers_new.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#make new dataframe and drop all NaN to see only the emails with connected account for further investigation\n",
    "df_vouchers_acc = df_vouchers_new\n",
    "df_vouchers_acc.dropna(inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check that correct amount of rows is left\n",
    "df_vouchers_acc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vouchers_acc.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vouchers_acc['email_hash'].nunique()\n",
    "#718 unique email_hash/accounts  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vouchers.email_hash.nunique()\n",
    "#5827 total unique email_hashs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_vouchers.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge accounts and vouchers, but only add the relevant column (voucherused)\n",
    "df_accounts = pd.merge(df_accounts, df_vouchers [['email_hash', 'voucherused']], on='email_hash', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accounts.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#add new column vouchers in accounts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add voucher information to accounts table - have to add both columns\n",
    "df_accounts = pd.merge(df_accounts, df_vouchers [['email_hash', 'voucherused']], left_on='email_hash', right_on='email_hash', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add voucher information to accounts table - have to add both columns\n",
    "# df_accounts = pd.merge(df_accounts, df_vouchers [['email_hash_receiver', 'voucher_used']], left_on='email_hash', right_on='email_hash_receiver', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop email_hash_receiver as it is not needed\n",
    "# df_accounts.drop('email_hash_receiver', axis=1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_accounts.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nf_base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ab3d85a18739f6fff6a9c8c504adc2ff9340867b576dede986e2ee74c099e4e5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
