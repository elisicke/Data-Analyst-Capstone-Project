{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "#import psycopg2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the get_engine function from our sql_functions.\n",
    "from sql_functions import get_engine #adjust this as necessary to match your sql_functions.py connection methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set paths to csv files\n",
    "accounts = './data/accounts.csv'\n",
    "playbacks = './data/playbacks.csv'\n",
    "subscriptions = './data/subscriptions.csv'\n",
    "vouchers = './data/promo_vouchers.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ACCOUNTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read accounts (21.10.2020 - 01.10.2022)\n",
    "df_accounts = pd.read_csv(accounts)\n",
    "# set column names to lowercase\n",
    "df_accounts.columns = df_accounts.columns.str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Postal Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove non numeric characters\n",
    "df_accounts['postal_code_clean'] = df_accounts['postal_code'].str.replace('-', '')\n",
    "df_accounts['postal_code_clean'] = df_accounts['postal_code_clean'].str.extract('(\\d+)')\n",
    "# fill null-values with 0\n",
    "df_accounts['postal_code_clean'].fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change data type to integer\n",
    "df_accounts['postal_code_clean'] = df_accounts['postal_code_clean'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## City"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mapping plz_files to accounts table for further geographical information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set file paths\n",
    "plz_ch = './data/plz_verzeichnis_ch.csv'\n",
    "plz_kanton = './data/plz_kantone_ch.csv'\n",
    "plz_de = './data/plz_verzeichnis_de.csv'\n",
    "plz_at = './data/plz_verzeichnis_at.csv'\n",
    "# read csv files\n",
    "df_plz_ch = pd.read_csv(plz_ch, sep=';')\n",
    "df_plz_kanton = pd.read_csv(plz_kanton, sep=';')\n",
    "df_plz_de = pd.read_csv(plz_de, sep=',')\n",
    "df_plz_at = pd.read_csv(plz_at, sep=';')\n",
    "# set column names to lowercase\n",
    "df_plz_ch.columns = df_plz_ch.columns.str.lower()\n",
    "df_plz_kanton.columns = df_plz_kanton.columns.str.lower()\n",
    "df_plz_de.columns = df_plz_de.columns.str.lower()\n",
    "df_plz_at.columns = df_plz_at.columns.str.lower()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean plz_kanton\n",
    "# only keep relevant columns, rename\n",
    "df_plz_kanton = df_plz_kanton[['postleitzahl / code postal / codice postale', 'ort / ville / città', 'kanton']]\n",
    "df_plz_kanton.rename(columns = {'postleitzahl / code postal / codice postale':'postal_code', 'ort / ville / città':'city', 'kanton':'state'}, inplace = True)\n",
    "df_plz_kanton.drop_duplicates(inplace = True)\n",
    "# add country_code for differentiation\n",
    "df_plz_kanton['country_code'] = 'CH'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean plz_de\n",
    "# only keep relevant columns, rename, drop duplicates\n",
    "df_plz_de = df_plz_de[['plz', 'ort', 'bundesland']]\n",
    "df_plz_de.rename(columns = {'plz':'postal_code', 'ort':'city', 'bundesland':'state'}, inplace = True)\n",
    "df_plz_de.drop_duplicates(inplace = True)\n",
    "# add country_code for differentiation\n",
    "df_plz_de['country_code'] = 'DE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean plz_at\n",
    "# only keep relevant columns, rename, drop duplicates\n",
    "df_plz_at = df_plz_at[['plz', 'ort', 'bundesland']]\n",
    "df_plz_at.rename(columns = {'plz':'postal_code', 'ort':'city', 'bundesland':'state'}, inplace = True)\n",
    "df_plz_at.drop_duplicates(inplace = True)\n",
    "# add country_code for differentiation\n",
    "df_plz_at['country_code'] = 'AT'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y8/hn189ww565g64x744hwbxyvm0000gp/T/ipykernel_82001/1600884800.py:4: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_plz_all = df_plz_all.groupby(['postal_code'])['city', 'state', 'country_code'].first().reset_index()\n"
     ]
    }
   ],
   "source": [
    "# unify for merging, check shape\n",
    "df_plz_all = pd.concat([df_plz_kanton, df_plz_de, df_plz_at])\n",
    "# dropping plz duplicates with multiple city, keeping the first entry each\n",
    "df_plz_all = df_plz_all.groupby(['postal_code'])['city', 'state', 'country_code'].first().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge city and state information to accounts table on plz and country code\n",
    "df_accounts = pd.merge(df_accounts, df_plz_all, left_on=['postal_code_clean', 'country_code'], right_on=['postal_code', 'country_code'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/y8/hn189ww565g64x744hwbxyvm0000gp/T/ipykernel_82001/222022654.py:8: FutureWarning: Indexing with multiple keys (implicitly converted to a tuple of keys) will be deprecated, use a list instead.\n",
      "  df_plz_ch = df_plz_ch.groupby(['postal_code'])['sprachcode', 'country_code'].first().reset_index()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nMapping of the language code:\\n#1 = German  \\n#2 = French  \\n#3 = Italian \\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# clean plz_a for language information\n",
    "# only keep relevant columns, rename, drop duplicates\n",
    "df_plz_ch = df_plz_ch[['postleitzahl', 'sprachcode']]\n",
    "df_plz_ch.rename(columns = {'postleitzahl':'postal_code'}, inplace = True)\n",
    "# add country_code for differentiation\n",
    "df_plz_ch['country_code'] = 'CH'\n",
    "#drop duplicates for dual-language-cities and keep first entry\n",
    "df_plz_ch = df_plz_ch.groupby(['postal_code'])['sprachcode', 'country_code'].first().reset_index()\n",
    "\n",
    "'''\n",
    "Mapping of the language code:\n",
    "#1 = German  \n",
    "#2 = French  \n",
    "#3 = Italian \n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge language code to accounts table\n",
    "df_accounts = pd.merge(df_accounts, df_plz_ch, left_on=['postal_code_clean', 'country_code'], right_on=['postal_code', 'country_code'], how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop duplicate postal code columns\n",
    "df_accounts = df_accounts.drop(['postal_code_x', 'postal_code_y', 'postal_code'], axis=1)\n",
    "#rename original postal code column\n",
    "df_accounts.rename(columns = {'postal_code_x':'postal_code_original', 'city_x':'city_original', 'city_y':'city_clean', 'sprachcode': 'language_code'}, inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Country_Code"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Add country name and region information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add country information\n",
    "country= './data/country_code.csv'\n",
    "df_country = pd.read_csv(country)\n",
    "# make column names lowercase\n",
    "df_country.columns = df_country.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only keep relevant columns, rename\n",
    "df_country = df_country[['name', 'alpha-2', 'region', 'sub-region']]\n",
    "df_country.rename(columns = {'alpha-2':'country_code', 'name':'country_name', 'sub-region':'sub_region'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merge to accounts_new table\n",
    "df_accounts = pd.merge(df_accounts, df_country, on='country_code', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fill null values\n",
    "df_accounts['language'].fillna('na', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PLAYBACKS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read playbacks\n",
    "df_playbacks = pd.read_csv(playbacks)\n",
    "# set column names to lowercase\n",
    "df_playbacks.columns = df_playbacks.columns.str.lower()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Changing datatypes and adding column playback_ID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing datatype to datetime\n",
    "df_playbacks['date_start'] = pd.to_datetime(df_playbacks['date_start'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# renaming columns\n",
    "df_playbacks.rename(columns = {'date_start':'datetime_start'}, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding date only column\n",
    "df_playbacks['date_start'] = pd.to_datetime(df_playbacks['datetime_start']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding playback_ID column and adding incremental nr as playback_ID to every row starting from the total count of rows, descending\n",
    "df_playbacks.insert(0, 'playback_ID', range(len(df_playbacks), 0, -1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Add category according to user_agent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>playback_ID</th>\n",
       "      <th>subscription_key</th>\n",
       "      <th>account_key</th>\n",
       "      <th>movie_id</th>\n",
       "      <th>date_start</th>\n",
       "      <th>playback_time</th>\n",
       "      <th>user_agent</th>\n",
       "      <th>ip_hash</th>\n",
       "      <th>date</th>\n",
       "      <th>app_user</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>device</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>desktop</th>\n",
       "      <td>116769</td>\n",
       "      <td>116769</td>\n",
       "      <td>116769</td>\n",
       "      <td>116769</td>\n",
       "      <td>116769</td>\n",
       "      <td>116769</td>\n",
       "      <td>116769</td>\n",
       "      <td>116769</td>\n",
       "      <td>116769</td>\n",
       "      <td>116769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mobile</th>\n",
       "      <td>22800</td>\n",
       "      <td>22800</td>\n",
       "      <td>22800</td>\n",
       "      <td>22800</td>\n",
       "      <td>22800</td>\n",
       "      <td>22800</td>\n",
       "      <td>22800</td>\n",
       "      <td>22800</td>\n",
       "      <td>22800</td>\n",
       "      <td>22800</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         playback_ID  subscription_key  account_key  movie_id  date_start  \\\n",
       "device                                                                      \n",
       "desktop       116769            116769       116769    116769      116769   \n",
       "mobile         22800             22800        22800     22800       22800   \n",
       "\n",
       "         playback_time  user_agent  ip_hash    date  app_user  \n",
       "device                                                         \n",
       "desktop         116769      116769   116769  116769    116769  \n",
       "mobile           22800       22800    22800   22800     22800  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#adding the infos about device of playback and app users\n",
    "df_playbacks.loc[df_playbacks['user_agent'].str.contains('Windows|Macintosh|TV|Linux|Darwin|CrOS|PlayStation|FreeBSD'), 'device'] = 'desktop'\n",
    "df_playbacks.loc[df_playbacks['user_agent'].str.contains('Android|iOS|iPhone|iPad'), 'device'] = 'mobile'\n",
    "df_playbacks.loc[df_playbacks['user_agent'].str.contains('filmingo'), 'app_user'] = 'yes'\n",
    "df_playbacks.loc[~df_playbacks['user_agent'].str.contains('filmingo'), 'app_user'] = 'no'\n",
    "df_playbacks.groupby('device').count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBSCRIPTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read subscriptions\n",
    "df_subscriptions = pd.read_csv(subscriptions)\n",
    "# set column names to lowercase\n",
    "df_subscriptions.columns = df_subscriptions.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set data types for subscription dates to datetime\n",
    "df_subscriptions['subscription_start'] = pd.to_datetime(df_subscriptions['subscription_start'])\n",
    "df_subscriptions['subscription_end'] = pd.to_datetime(df_subscriptions['subscription_end'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop \"wrong\" subscription type line (FULLACCESS - unknown type to us - only one line therefore decided to drop)\n",
    "df_subscriptions.drop(df_subscriptions[(df_subscriptions['subscription_type'] == 'FULLACCESS')].index, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column and calculate subscription duration\n",
    "df_subscriptions['subscription_months_raw'] = ((df_subscriptions.subscription_end) - df_subscriptions.subscription_start)/np.timedelta64(1, 'M')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create new column for rounded subscription months for easier further processing\n",
    "#generally round up from 0.1 to be able to allow some discrepancies due to day to day calculation of subscription duration (deduct 0.1 to be able to use .ceil)\n",
    "df_subscriptions['subscription_months'] = df_subscriptions['subscription_months_raw'] - 0.1\n",
    "df_subscriptions['subscription_months'] = df_subscriptions['subscription_months'].apply(np.ceil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two columns for chf and eur based on the subscription_type and prices from the filmingo website\n",
    "\n",
    "# create a list of the conditions\n",
    "conditions = [\n",
    "    ((df_subscriptions['subscription_type'] == 'BASIC') & (df_subscriptions['subscription_monthly'] == 0)),\n",
    "    ((df_subscriptions['subscription_type'] == 'BASIC') & (df_subscriptions['subscription_monthly'] == 1)),\n",
    "    ((df_subscriptions['subscription_type'] == 'STANDARD') & (df_subscriptions['subscription_monthly'] == 0)),\n",
    "    ((df_subscriptions['subscription_type'] == 'STANDARD') & (df_subscriptions['subscription_monthly'] == 1)),\n",
    "    ((df_subscriptions['subscription_type'] == 'PATRON') & (df_subscriptions['subscription_monthly'] == 0))\n",
    "\n",
    "]\n",
    "\n",
    "# create a list of the values we want to assign for each condition\n",
    "values_chf = ['90.0', '9.0', '150.0', '15.0', '240.0']\n",
    "values_eur = ['75.0', '7.5', '125.0', '12.5', '200.0']\n",
    "\n",
    "# create a new column and use np.select to assign values to it using our lists as arguments\n",
    "df_subscriptions['price_chf'] = np.select(conditions, values_chf)\n",
    "df_subscriptions['price_eur'] = np.select(conditions, values_eur)\n",
    "\n",
    "#change datatype into float for further calculation\n",
    "df_subscriptions['price_chf'] = df_subscriptions.price_chf.astype('float')\n",
    "df_subscriptions['price_eur'] = df_subscriptions.price_eur.astype('float')\n",
    "\n",
    "# decided to use these prices for all subscriptions regardless if they might have a different prices in the list (possibly due to discounts, total lines of abnormal prices: 39) or are gifted subscription (price: NaN, total lines 1.636)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculate total price per subscription (price / 12 * subscription months)\n",
    "df_subscriptions['total_price_chf'] = df_subscriptions['price_chf'] / 12 * df_subscriptions['subscription_months']\n",
    "df_subscriptions['total_price_eur'] = df_subscriptions['price_eur'] / 12 * df_subscriptions['subscription_months']\n",
    "\n",
    "\n",
    "# conditional calculation for exceptions:\n",
    "\n",
    "# if the subscription is monthly only calculate price * months\n",
    "df_subscriptions.loc[(df_subscriptions['subscription_monthly'] == 1), 'total_price_chf'] = (df_subscriptions['price_chf'] * df_subscriptions['subscription_months'])\n",
    "df_subscriptions.loc[(df_subscriptions['subscription_monthly'] == 1), 'total_price_eur'] = (df_subscriptions['price_eur'] * df_subscriptions['subscription_months'])\n",
    "\n",
    "# if the subscription is gifted & 6 months long, a different price is applicable (there is only a 6 month subscription available for gifted subscriptions)\n",
    "df_subscriptions.loc[((df_subscriptions['gift_subscription'] == True) & (df_subscriptions['subscription_months'] == 6)), 'total_price_chf'] = '49'\n",
    "df_subscriptions.loc[((df_subscriptions['gift_subscription'] == True) & (df_subscriptions['subscription_months'] == 6)), 'total_price_eur'] = '41'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VOUCHERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read promo_couchers\n",
    "df_vouchers = pd.read_csv(vouchers, sep=';')\n",
    "# set column names to lowercase\n",
    "df_vouchers.columns = df_vouchers.columns.str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changing datatype to datetime\n",
    "df_vouchers['creationdate'] = pd.to_datetime(df_vouchers['creationdate'])\n",
    "df_vouchers['expirationdate'] = pd.to_datetime(df_vouchers['expirationdate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#cut off time of creation -> time not relevant? \n",
    "#df_vouchers['creationdate'] = df_vouchers['creationdate'].dt.date -> does not work very well as it returns an object\n",
    "df_vouchers['creationdate'] = df_vouchers['creationdate'].dt.normalize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding playback_ID column and adding incremental nr as playback_ID to every row starting from 1, ascending\n",
    "df_vouchers.insert(0, 'voucher_ID', range(1, 1 + len(df_vouchers)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#rename columns\n",
    "df_vouchers.rename(columns = {'account_key':'account_key_sender', 'email_hash':'email_hash_receiver', 'voucherused': 'voucher_used', 'creationdate': 'creation_date', 'expirationdate': 'expiration_date'}, inplace = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add voucher information to accounts table - only take into account unique email_hash_receiver (drop duplicates)\n",
    "df_accounts = df_accounts.merge(df_vouchers.drop_duplicates('email_hash_receiver')[['email_hash_receiver', 'voucher_used']], how='left', left_on='email_hash', right_on='email_hash_receiver')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#drop email_hash_receiver as it is not needed\n",
    "df_accounts.drop('email_hash_receiver', axis=1, inplace = True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATE TABLE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_date = pd.DataFrame({\"Date\": pd.date_range('2020-01-01','2022-12-31')})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PUSH DATA TO SQL SERVER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = 'capstone_filmingo' # UPDATE 'TABLE_SCHEMA' based on schema used in class \n",
    "engine = get_engine() # assign engine to be able to query against the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>account_key</th>\n",
       "      <th>city_original</th>\n",
       "      <th>language</th>\n",
       "      <th>country_code</th>\n",
       "      <th>email_hash</th>\n",
       "      <th>onetime_rental_count</th>\n",
       "      <th>subscription_count</th>\n",
       "      <th>postal_code_clean</th>\n",
       "      <th>city_clean</th>\n",
       "      <th>state</th>\n",
       "      <th>language_code</th>\n",
       "      <th>country_name</th>\n",
       "      <th>region</th>\n",
       "      <th>sub_region</th>\n",
       "      <th>voucher_used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60a90104f44414d9036aed7d96d1468a5a9e1d104b6791...</td>\n",
       "      <td>Wettingen</td>\n",
       "      <td>de</td>\n",
       "      <td>CH</td>\n",
       "      <td>5f3d193f5be5c279e77a80d7de82ffb34e3883a3d6a3e7...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>5430</td>\n",
       "      <td>Wettingen</td>\n",
       "      <td>Aargau</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a48b28809457e680de54b4b560e00117308431c574aab2...</td>\n",
       "      <td>Meilen</td>\n",
       "      <td>de</td>\n",
       "      <td>CH</td>\n",
       "      <td>029a26c1483d78f98002c3be1c902b15ce814b62e45a2a...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>8706</td>\n",
       "      <td>Meilen</td>\n",
       "      <td>Zürich</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7a280859423057ac5f1e0bfc15af602edd23900f3cf7cb...</td>\n",
       "      <td>Lausanne</td>\n",
       "      <td>fr</td>\n",
       "      <td>CH</td>\n",
       "      <td>08a8ff8a3b3fb9be3a8f87a86960bf9f3e43b31d0772e1...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1005</td>\n",
       "      <td>Lausanne</td>\n",
       "      <td>Waadt</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>23e7ac18b391549e95a98d85a3adae1f3f90c4fcc09732...</td>\n",
       "      <td>Oberdorf</td>\n",
       "      <td>de</td>\n",
       "      <td>CH</td>\n",
       "      <td>007ada12068218817c2b69325d1bfe2d7ac10da3a9922d...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4436</td>\n",
       "      <td>Liedertswil</td>\n",
       "      <td>Basel-Landschaft</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>a39dbaa7972fb67c15db79d4a66cf5d1b94855ae530774...</td>\n",
       "      <td>Luzern</td>\n",
       "      <td>de</td>\n",
       "      <td>CH</td>\n",
       "      <td>cff18967fb0f8b29eeb54a91b98d027920d44c1e771258...</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>6005</td>\n",
       "      <td>Luzern</td>\n",
       "      <td>Luzern</td>\n",
       "      <td>1.0</td>\n",
       "      <td>Switzerland</td>\n",
       "      <td>Europe</td>\n",
       "      <td>Western Europe</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         account_key city_original language  \\\n",
       "0  60a90104f44414d9036aed7d96d1468a5a9e1d104b6791...     Wettingen       de   \n",
       "1  a48b28809457e680de54b4b560e00117308431c574aab2...        Meilen       de   \n",
       "2  7a280859423057ac5f1e0bfc15af602edd23900f3cf7cb...      Lausanne       fr   \n",
       "3  23e7ac18b391549e95a98d85a3adae1f3f90c4fcc09732...      Oberdorf       de   \n",
       "4  a39dbaa7972fb67c15db79d4a66cf5d1b94855ae530774...        Luzern       de   \n",
       "\n",
       "  country_code                                         email_hash  \\\n",
       "0           CH  5f3d193f5be5c279e77a80d7de82ffb34e3883a3d6a3e7...   \n",
       "1           CH  029a26c1483d78f98002c3be1c902b15ce814b62e45a2a...   \n",
       "2           CH  08a8ff8a3b3fb9be3a8f87a86960bf9f3e43b31d0772e1...   \n",
       "3           CH  007ada12068218817c2b69325d1bfe2d7ac10da3a9922d...   \n",
       "4           CH  cff18967fb0f8b29eeb54a91b98d027920d44c1e771258...   \n",
       "\n",
       "   onetime_rental_count  subscription_count  postal_code_clean   city_clean  \\\n",
       "0                     0                   1               5430    Wettingen   \n",
       "1                     0                   1               8706       Meilen   \n",
       "2                     1                   0               1005     Lausanne   \n",
       "3                     0                   2               4436  Liedertswil   \n",
       "4                     8                   2               6005       Luzern   \n",
       "\n",
       "              state  language_code country_name  region      sub_region  \\\n",
       "0            Aargau            1.0  Switzerland  Europe  Western Europe   \n",
       "1            Zürich            1.0  Switzerland  Europe  Western Europe   \n",
       "2             Waadt            2.0  Switzerland  Europe  Western Europe   \n",
       "3  Basel-Landschaft            1.0  Switzerland  Europe  Western Europe   \n",
       "4            Luzern            1.0  Switzerland  Europe  Western Europe   \n",
       "\n",
       "   voucher_used  \n",
       "0           NaN  \n",
       "1           NaN  \n",
       "2           NaN  \n",
       "3           NaN  \n",
       "4           0.0  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_accounts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Accounts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The accounts table was imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Specify which table within your database you want to push your data to. Give your table an unambiguous name.\n",
    "table_name = 'accounts'\n",
    "# If the specified table doesn't exist yet, it will be created\n",
    "# With 'replace', your data will be replaced if the table already exists.\n",
    "# This may take some time ...\n",
    "\n",
    "# Write records stored in a dataframe to SQL database\n",
    "if engine!=None:\n",
    "    try:\n",
    "        df_accounts.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schema that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None\n",
    "else:\n",
    "     print('Push did not work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to be sure: Check if the number of rows match\n",
    "table_name_sql = f'''SELECT count(*) \n",
    "                    FROM {schema}.{table_name}\n",
    "                    '''\n",
    "engine.execute(table_name_sql).fetchall()[0][0] == df_accounts.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Subscriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The subscriptions table was imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Specify which table within your database you want to push your data to. Give your table an unambiguous name.\n",
    "table_name = 'subscriptions'\n",
    "# If the specified table doesn't exist yet, it will be created\n",
    "# With 'replace', your data will be replaced if the table already exists.\n",
    "# This may take some time ...\n",
    "\n",
    "# Write records stored in a dataframe to SQL database\n",
    "if engine!=None:\n",
    "    try:\n",
    "        df_subscriptions.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None\n",
    "else:\n",
    "     print('Push did not work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to be sure: Check if the number of rows match\n",
    "table_name_sql = f'''SELECT count(*) \n",
    "                    FROM {schema}.{table_name}\n",
    "                    '''\n",
    "engine.execute(table_name_sql).fetchall()[0][0] == df_subscriptions.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Playback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The playbacks table was imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Specify which table within your database you want to push your data to. Give your table an unambiguous name.\n",
    "table_name = 'playbacks'\n",
    "# If the specified table doesn't exist yet, it will be created\n",
    "# With 'replace', your data will be replaced if the table already exists.\n",
    "# This may take some time ...\n",
    "\n",
    "# Write records stored in a dataframe to SQL database\n",
    "if engine!=None:\n",
    "    try:\n",
    "        df_playbacks.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None\n",
    "else:\n",
    "     print('Push did not work')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to be sure: Check if the number of rows match\n",
    "table_name_sql = f'''SELECT count(*) \n",
    "                    FROM {schema}.{table_name}\n",
    "                    '''\n",
    "engine.execute(table_name_sql).fetchall()[0][0] == df_playbacks.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Promo Voucher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The vouchers table was imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Specify which table within your database you want to push your data to. Give your table an unambiguous name.\n",
    "table_name = 'vouchers'\n",
    "# If the specified table doesn't exist yet, it will be created\n",
    "# With 'replace', your data will be replaced if the table already exists.\n",
    "# This may take some time ...\n",
    "\n",
    "# Write records stored in a dataframe to SQL database\n",
    "if engine!=None:\n",
    "    try:\n",
    "        df_vouchers.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None\n",
    "else:\n",
    "     print('Push did not work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to be sure: Check if the number of rows match\n",
    "table_name_sql = f'''SELECT count(*) \n",
    "                    FROM {schema}.{table_name}\n",
    "                    '''\n",
    "engine.execute(table_name_sql).fetchall()[0][0] == df_vouchers.shape[0]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Date Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The date table was imported successfully.\n"
     ]
    }
   ],
   "source": [
    "# Specify which table within your database you want to push your data to. Give your table an unambiguous name.\n",
    "table_name = 'date'\n",
    "# If the specified table doesn't exist yet, it will be created\n",
    "# With 'replace', your data will be replaced if the table already exists.\n",
    "# This may take some time ...\n",
    "\n",
    "# Write records stored in a dataframe to SQL database\n",
    "if engine!=None:\n",
    "    try:\n",
    "        df_date.to_sql(name=table_name, # Name of SQL table\n",
    "                        con=engine, # Engine or connection\n",
    "                        if_exists='replace', # Drop the table before inserting new values \n",
    "                        schema=schema, # Use schmea that was defined earlier\n",
    "                        index=False, # Write DataFrame index as a column\n",
    "                        chunksize=5000, # Specify the number of rows in each batch to be written at a time\n",
    "                        method='multi') # Pass multiple values in a single INSERT clause\n",
    "        print(f\"The {table_name} table was imported successfully.\")\n",
    "    # Error handling\n",
    "    except (Exception, psycopg2.DatabaseError) as error:\n",
    "        print(error)\n",
    "        engine = None\n",
    "else:\n",
    "     print('Push did not work')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Just to be sure: Check if the number of rows match\n",
    "table_name_sql = f'''SELECT count(*) \n",
    "                    FROM {schema}.{table_name}\n",
    "                    '''\n",
    "engine.execute(table_name_sql).fetchall()[0][0] == df_date.shape[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('nf_sql')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a81d278bed5b5b59425dcb5a82ce505657686243c184b4a6b67e69d01c4d432e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
